[
["index.html", "Impact Evaluation in Practice Solutions for Second Edition in R Preamble", " Impact Evaluation in Practice Solutions for Second Edition in R Liam F. Beiser-McGrath Lecturer (Assistant Professor) in Politics, Royal Holloway, University of London www.liambeisermcgrath.com liam@liambeisermcgrath.com 2020-07-29 Preamble This online book consists of the solutions for the (fictional) HISP program evaluation example used throughout the great (free!) book Impact Evaluation in Practice (2nd Edition) by Gertler, Martinez, Premand, Rawlings, and Vermeersch released by the World Bank Group and the Inter-American Development Bank. https://openknowledge.worldbank.org/handle/10986/25030 These solutions are part translation/extension of the original Stata code, part relevant extracts from the book, and some additions I made when teaching this material. As you’ll see, the code generally follows the tidyverse approach to R, with some exceptions here and there. Usual caveats apply. "],
["about-the-author.html", "About the Author", " About the Author Liam F. Beiser-McGrath is a Lecturer (Assistant Professor) in Politics at Royal Holloway, University of London. They are also a Senior Research Fellow at Universität Konstanz and Research Associate at ETH Zürich. Their research primarily focuses on the political economy of climate change, using experimental research designs and machine learning. This research has been published in peer-reviewed journals such as Science Advances, Nature Climate Change, Political Analysis, Regulation and Governance, Political Science Research &amp; Methods, and Climatic Change. For further information please visit www.liambeisermcgrath.com "],
["intro.html", "Chapter 1 Introduction 1.1 Variable Definitions", " Chapter 1 Introduction In this chapter we load all the packages and data we’ll be using throughout the book. We also provide descriptions of the variables that form the (fictional) HISP program evaluation data set. You can download the data from the GitHub repo associated with this book: https://github.com/lfbeisermcgrath/rimpactevaluation/tree/master/data # Loading of packages, data, and seed setting here library(broom) library(clusterPower) library(estimatr) library(fishmethods) library(haven) library(kableExtra) library(MatchIt) library(modelsummary) library(pwr) library(rddensity) library(skimr) library(texreg) library(tidyverse) df &lt;- read_dta(&quot;./data/evaluation.dta&quot;) vars &lt;- read_csv(&quot;./data/variable_desc.csv&quot;) theme_set(ggpubr::theme_pubclean()) # subset data to only &quot;eligible&quot; units df_elig &lt;- df %&gt;% filter(eligible == 1) The dataset is at the level of household and round. This means that one observation (row) captures information for one household either in the baseline (round 0) or in the follow- up survey (round 1). In other words, every household appears on two rows: one for the baseline and one for the follow-up survey. 1.1 Variable Definitions 1.1.1 Outcome Variable variable description health_expenditures Out of pocket health expenditures (per person per year) 1.1.2 Control Variables variable description age_hh Age of the head of the household (in years) age_sp Age of the spouse (in years) educ_hh Education of the head of household (completed years of schooling) educ_sp Education of the spouse (completed years of schooling) female_hh Head of the household is a woman (0=no 1=yes) indigenous Head of household speaks an indigenous language (0=no 1=yes) hhsize Number of household members (baseline) dirtfloor Home has a dirt floor at baseline (0=no 1=yes) bathroom Home with private bathroom at baseline (0=no 1=yes) land Number of hectares of land owned by household at baseline 1.1.3 Other Variables variable description locality_identifier Locality identifier household_identifier Unique household identifier treatment_locality Household is located in treatment community (0=no 1=yes) promotion_locality Household is located in promoted community (0=no 1=yes) eligible Household eligible to enroll in HISP (0=no 1=yes) enrolled HH enrolled in HISP (0=no 1=yes) enrolled_rp Household enrolled in HISP under the random promotion scenario (0=no 1=yes) poverty_index Poverty Index 1-100 round Survey round (0 = baseline; 1 = follow-up) hospital HH member visited hospital in the past year (0=no 1=yes) "],
["causal-inference-and-counterfactuals.html", "Chapter 2 Causal Inference and Counterfactuals 2.1 Before-After Designs 2.2 Enrolled vs. Non-Enrolled", " Chapter 2 Causal Inference and Counterfactuals 2.1 Before-After Designs The first “expert” consultant you hire indicates that to estimate the impact of HISP, you must calculate the change in health expenditures over time for the households that enrolled. The consultant argues that because HISP covers all health costs, any decrease in expenditures over time must be attributable to the effect of HISP. Using the subset of enrolled households, you calculate their average health expenditures before the implementation of the program and then again two years later. Compare average household health expenditures before and after being enrolled in the program in villages covered by HISP. m_ba1 &lt;- lm_robust(health_expenditures ~ round, clusters = locality_identifier, data = df %&gt;% filter(treatment_locality==1 &amp; enrolled ==1)) m_ba2 &lt;- lm_robust(health_expenditures ~ round + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance, clusters = locality_identifier, data = df %&gt;% filter(treatment_locality==1 &amp; enrolled ==1)) htmlreg(list(m_ba1, m_ba2), doctype = FALSE, custom.model.names = c(&quot;No Controls&quot;, &quot;With Controls&quot;), custom.coef.map = list(&#39;round&#39; = &quot;Post-Enrollment&quot;, &#39;(Intercept)&#39; = &quot;Intercept&quot;), caption = &quot;Change in Health Expenditures for Households Enrolled in Program&quot;, caption.above = TRUE) Change in Health Expenditures for Households Enrolled in Program No Controls With Controls Post-Enrollment -6.65* -6.71* [-7.11; -6.19] [-7.17; -6.25] Intercept 14.49* 24.73* [14.20; 14.78] [23.54; 25.92] R2 0.21 0.48 Adj. R2 0.21 0.48 Num. obs. 5929 5929 RMSE 6.44 5.22 N Clusters 98 98 * Null hypothesis value outside the confidence interval. Does the before-and-after comparison control for all the factors that affect health expenditures over time? No, it is very unlikely that this analysis controls for all the factors that may impact health expenditures over time. For example, there are other health interventions operating simultaneously in the villages receiving HISP, which could also have caused increases or decreases in health expenditures. Additionally, a financial crisis in the country could have reduced health expenditures, meaning that in the absence of HISP, households might have spent less on health. Based on these results produced by the before-and-after analysis, should HISP be scaled up nationally? No, based on these results HISP should not be scaled up nationally. The program decreased average health expenditures in poor households, but by much less than the threshold level of $10 that was determined by the government. 2.2 Enrolled vs. Non-Enrolled Another consultant suggests that it would be more appropriate to estimate the counterfactual in the post-intervention period: that is, two years after the program started. The consultant correctly notes that of the 4,959 households in the baseline sample, only 2,907 actually enrolled in the program, so approximately 41 percent of the households in the sample remain without HISP coverage. The consultant argues that all households within the 100 pilot villages were eligible to enroll. These households all share the same health clinics and are subject to the same local prices for pharmaceuticals. Moreover, most households are engaged in similar economic activities. The consultant argues that in these circumstances, the outcomes of the nonenrolled group after the intervention could serve to estimate the counterfactual outcome of the group enrolled in HISP. You therefore decide to calculate average health expenditures in the post-intervention period for both the households that enrolled in the program and the households that did not. m_ene1 &lt;- lm_robust(health_expenditures ~ enrolled, clusters = locality_identifier, data = df %&gt;% filter(treatment_locality==1 &amp; round ==1)) m_ene2 &lt;- lm_robust(health_expenditures ~ enrolled + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance, clusters = locality_identifier, data = df %&gt;% filter(treatment_locality==1 &amp; round ==1)) htmlreg(list(m_ene1, m_ene2), doctype = FALSE, custom.model.names = c(&quot;No Controls&quot;, &quot;With Controls&quot;), custom.coef.map = list(&#39;enrolled&#39; = &quot;Enrollment&quot;, &#39;(Intercept)&#39; = &quot;Intercept&quot;), caption = &quot;Difference in Health Expenditures Between Households Enrolled and Not Enrolled in Program&quot;, caption.above = TRUE) Difference in Health Expenditures Between Households Enrolled and Not Enrolled in Program No Controls With Controls Enrollment -14.46* -9.98* [-15.13; -13.80] [-10.58; -9.39] Intercept 22.30* 30.35* [ 21.63; 22.98] [ 27.87; 32.82] R2 0.33 0.45 Adj. R2 0.33 0.45 Num. obs. 4960 4960 RMSE 10.18 9.17 N Clusters 100 100 * Null hypothesis value outside the confidence interval. Does this analysis likely control for all the factors that determine differences in health expenditures between the two groups? No, it is unlikely that the multivariate analysis controls for all the factors that impact health expenditures between the two groups. There may be unobservable factors that determine why some households enroll in HISP and others to not, such as personal preferences on health or the motivation of the household decision maker. Based on these results produced by the enrolled-nonenrolled method, should the HISP be scaled up nationally? Based strictly on the estimate from the multivariate linear regression, the HISP should not be scaled up nationally because it decreased health expenditures by $ 9.98, which is less than the government-determined threshold level of $10. However, the $9.98 estimate is very close to $10. In statistical terms, it is not statistically different from $10. Therefore, you might still argue that the HISP should be expanded nationally. "],
["randomised-assignment.html", "Chapter 3 Randomised Assignment", " Chapter 3 Randomised Assignment Having conducted two impact assessments using potentially biased estimators of the counterfactual in chapter 3 (with conflicting policy recommendations), you decide to go back to the drawing board to rethink how to obtain a more precise estimate of the counterfactual. After further deliberations with your evaluation team, you are convinced that constructing a valid estimate of the counterfactual will require identifying a group of villages that are as similar as possible to the 100 treatment villages in all respects, except that one group took part in HISP and the other did not. Because HISP was rolled out as a pilot, and the 100 treatment villages were selected randomly from among all of the rural villages in the country, you note that the treatment villages should, on average, have the same characteristics as the untreated rural villages in the country. The counterfactual can therefore be estimated in a valid way by measuring the health expenditures of eligible households in rural villages that did not take part in the program. Luckily, at the time of the baseline and follow-up surveys, the survey firm collected data on an additional 100 rural villages that were not offered the program. Those 100 villages were also randomly selected from the population of rural villages in the country. Thus the way that the two groups of villages were chosen ensures that they have statistically identical characteristics, except that the 100 treatment villages received HISP and the 100 comparison villages did not. Randomized assignment of the treatment has occurred. Given randomized assignment of treatment, you are quite confident that no external factors other than HISP would explain any differences in outcomes between the treatment and comparison villages. To validate this assumption, test whether eligible households in the treatment and comparison villages have similar characteristics at baseline. df_elig %&gt;% filter(round == 0) %&gt;% dplyr::select(treatment_locality, locality_identifier, age_hh, age_sp, educ_hh, educ_sp, female_hh, indigenous, hhsize, dirtfloor, bathroom, land, hospital_distance) %&gt;% tidyr::pivot_longer(-c(&quot;treatment_locality&quot;,&quot;locality_identifier&quot;)) %&gt;% group_by(name) %&gt;% do(tidy(lm_robust(value ~ treatment_locality, data = .))) %&gt;% filter(term == &quot;treatment_locality&quot;) %&gt;% dplyr::select(name, estimate, std.error, p.value) %&gt;% kable() name estimate std.error p.value age_hh -0.6354625 0.3759583 0.0910361 age_sp -0.0386302 0.3120790 0.9014911 bathroom 0.0149907 0.0132340 0.2573724 dirtfloor -0.0129497 0.0118744 0.2755159 educ_hh 0.1607976 0.0697576 0.0211978 educ_sp 0.0289107 0.0670018 0.6661273 female_hh -0.0041155 0.0070493 0.5593691 hhsize 0.0596953 0.0530454 0.2604833 hospital_distance 2.9087631 1.1323148 0.0102288 indigenous 0.0091048 0.0131969 0.4902756 land -0.0402168 0.0704607 0.5681787 You observe that the average characteristics of households in the treatment and comparison villages are in fact very similar. The only statistically significant differences are for the number of years of education of the head of household and distance to hospital, and those differences are small (only 0.16 years, or less than 6 percent of the comparison group’s average years of education, and 2.91 kilometers, or less than 3 percent of the comparison group’s average distance to a hospital). Even with a randomized experiment on a large sample, a small number of differences can be expected because of chance andthe properties of the statistical test. In fact, using standard significance levels of 5 percent we could expect differences in about 5 percent of characteristics to be statistically significant, though we would not expect the magnitude of these differences to be large. Estimate the average household health expenditures for eligible households in the treatment and comparison villages for each period. What is the impact of the program? out_round0 &lt;- lm_robust(health_expenditures ~ treatment_locality, data = df_elig %&gt;% filter(round == 0), clusters = locality_identifier) out_round1 &lt;- lm_robust(health_expenditures ~ treatment_locality, data = df_elig %&gt;% filter(round == 1), clusters = locality_identifier) htmlreg(list(out_round0, out_round1), doctype = FALSE, custom.coef.map = list(`treatment_locality` = &quot;Treatment Village&quot;, `(Intercept)` = &quot;Intercept&quot;), custom.model.names = c(&quot;Baseline&quot;, &quot;Follow Up&quot;), caption = &quot;Health Expenditures by Treatment Locality&quot;) Health Expenditures by Treatment Locality Baseline Follow Up Treatment Village -0.08 -10.14* [-0.51; 0.34] [-10.93; -9.35] Intercept 14.57* 17.98* [14.26; 14.89] [ 17.36; 18.60] R2 0.00 0.30 Adj. R2 -0.00 0.30 Num. obs. 5628 5629 RMSE 4.30 7.73 N Clusters 197 197 * Null hypothesis value outside the confidence interval. With the validity of the comparison group established, you can now estimate the counterfactual as the average health expenditures of eligible households in the 100 comparison villages. Table X shows the average household health expenditures for eligible households in the treatment and comparison villages. You note that at baseline, the average household health expenditures in the treatment and comparison groups are not sta- tistically different, as should be expected under randomized assignment. Given that you now have a valid comparison group, you can find the impact of the HISP simply by taking the difference between the average out-of-pocket health expenditures of households in the treatment villages and randomly assigned comparison villages in the follow-up period. The impact is a reduction of US$10.14 over two years. Re-estimate using a multivariate regression analysis that controls for the other observable characteristics of the sample households. How does your impact estimate change? out_round1_nocov &lt;- lm_robust(health_expenditures ~ treatment_locality, data = df_elig %&gt;% filter(round == 1), clusters = locality_identifier) out_round1_wcov &lt;- lm_robust(health_expenditures ~ treatment_locality + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance, data = df_elig %&gt;% filter(round == 1), clusters = locality_identifier) htmlreg(list(out_round1_nocov, out_round1_wcov), doctype = FALSE, custom.coef.map = list(`treatment_locality` = &quot;Treatment Village&quot;, `(Intercept)` = &quot;Intercept&quot;), custom.model.names = c(&quot;No Covariate Adjust.&quot;, &quot;With Covariate Adjust.&quot;), caption = &quot;Evaluating HISP: Randomized Assignment with Regression Analysis&quot;) Evaluating HISP: Randomized Assignment with Regression Analysis No Covariate Adjust. With Covariate Adjust. Treatment Village -10.14* -10.01* [-10.93; -9.35] [-10.70; -9.32] Intercept 17.98* 27.57* [ 17.36; 18.60] [ 25.83; 29.30] R2 0.30 0.43 Adj. R2 0.30 0.43 Num. obs. 5629 5629 RMSE 7.73 6.98 N Clusters 197 197 * Null hypothesis value outside the confidence interval. Replicating this result through a linear regression analysis yields the same result, as shown in Table X. Finally, you run a multivariate regression analysis that controls for some other observable characteristics of the sample house- holds, and you find that the program has reduced the expenditures of the enrolled households by US$10.01 over two years, which is nearly identi- cal to the linear regression result. With randomized assignment, we can be confident that no factors are present that are systematically different between the treatment and comparison groups that might also explain the difference in health expenditures. Both sets of villages started off with very similar average characteristics and have been exposed to the same set of national policies and programs during the two years of treatment. Thus the only plausible reason that poor households in treatment communities have lower expenditures than households in compari- son villages is that the first group received the health insurance program and the other group did not. Why is the impact estimate derived using a multivariate linear regression basically unchanged when controlling for other factors, compared to the simple linear regression and comparison of means? Because the treatment was assigned randomly, the comparison and treatment groups should have identical characteristics and be exposed to the same external factors over time. The only difference between the two groups is that the treatment group received HISP. Because of the randomized assignment process, the characteristics (controls) of the treatment and comparison group are unrelated to treatment status, so controlling for additional characteristics in the multivariate linear regression is not expected to change the estimated impact by much. Based on the impact estimated with the randomized assignment method, should the HISP be scaled up nationally? Yes, based on this result, the HISP should be scaled up nationally because it decreased health expenditures by more than the $10 threshold level. "],
["instrumental-variables.html", "Chapter 4 Instrumental Variables", " Chapter 4 Instrumental Variables Let us now try using the randomized promotion method to evaluate the impact of the Health Insurance Subsidy Program (HISP). Assume that the ministry of health makes an executive decision that the health insurance subsidy should be made available immediately to any household that wants to enroll. You note that this is a different scenario than the randomized assignment case we have considered so far. However, you know that realistically this national scale-up will be incremental over time, so you reach an agreement to try and accelerate enrollment in a random subset of villages through a promotion campaign. In a random subsample of villages (indicated by promotion_locality), you undertake an intensive promotion effort that includes communication and social marketing aimed at increasing awareness of HISP. The promotion activities are carefully designed to avoid content that may inadvertently encourage changes in other health-related behaviors, since this would invalidate the promotion as an instrumental variable (IV). Instead, the promotion concentrates exclusively on boosting enrollment in HISP. What was the effect of the promotion campaign upon enrollment? Note you should use the variable enrolled_rp for this question m_enroll &lt;- lm_robust(enrolled_rp ~ promotion_locality, clusters = locality_identifier, data = df %&gt;% filter(round == 1)) htmlreg(m_enroll, doctype = FALSE, custom.coef.map = list(`promotion_locality` = &quot;Promotion Locality&quot;, `(Intercept)` = &quot;Intercept&quot;), caption = &quot;Randomized Promotion Comparison of Enrollment Rate in HISP&quot;, custom.model.names = &quot;Enrollment Rate&quot;) Randomized Promotion Comparison of Enrollment Rate in HISP Enrollment Rate Promotion Locality 0.41* [0.34; 0.48] Intercept 0.08* [0.04; 0.13] R2 0.20 Adj. R2 0.20 Num. obs. 9914 RMSE 0.41 N Clusters 200 * 0 outside the confidence interval. After two years of promotion and program implementation, you find that 0.49 percent of households in villages that were randomly assigned to the promotion have enrolled in the program, while only 0.08 percent of households in non-promoted villages have enrolled. Because the promoted and nonpromoted villages were assigned at random, you know that the average characteristics of the two groups should be the same in the absence of the promotion. You can verify that assumption by comparing the baseline health expenditures (as well as any other characteristics) of the two populations. Compare baseline healthcare expenditures based upon assignment to promotion. m_base_health &lt;- lm_robust(health_expenditures ~ promotion_locality, clusters = locality_identifier, data = df %&gt;% filter(round == 0) ) htmlreg(m_base_health, doctype = FALSE, custom.coef.map = list(`promotion_locality` = &quot;Promotion Locality&quot;, `(Intercept)` = &quot;Intercept&quot;), caption = &quot;Randomized Promotion Comparison of Mean Household Expenditures at Baseline&quot;, custom.model.names = &quot;Household Expenditures at Baseline&quot;) Randomized Promotion Comparison of Mean Household Expenditures at Baseline Household Expenditures at Baseline Promotion Locality -0.05 [-0.62; 0.51] Intercept 17.24* [16.76; 17.71] R2 0.00 Adj. R2 -0.00 Num. obs. 9913 RMSE 5.59 N Clusters 200 * 0 outside the confidence interval. Estimate the difference in health expenditures by assignment to promotion, in the post-treatment period m_post_health &lt;- lm_robust(health_expenditures ~ promotion_locality, clusters = locality_identifier, data = df %&gt;% filter(round == 1) ) htmlreg(m_post_health, doctype = FALSE, custom.coef.map = list(`promotion_locality` = &quot;Promotion Locality&quot;, `(Intercept)` = &quot;Intercept&quot;), caption = &quot;Randomized Promotion Comparison of Mean Household Expenditures at Follow-Up&quot;, custom.model.names = &quot;Household Expenditures at Follow-Up&quot;) Randomized Promotion Comparison of Mean Household Expenditures at Follow-Up Household Expenditures at Follow-Up Promotion Locality -3.87* [-5.14; -2.61] Intercept 18.85* [17.87; 19.82] R2 0.03 Adj. R2 0.03 Num. obs. 9914 RMSE 11.73 N Clusters 200 * 0 outside the confidence interval. Using this health expenditure estimate and the estimated proportion of “compliers”, estimate the LATE/CACE After two years of program implementation, you observe that the average health expenditure in the promoted villages is 14.97 USD, compared with 18.85 USD in nonpromoted areas (a difference of -3.87 USD). However, because the only difference between the promoted and nonpromoted villages is that enrollment in the program is higher in the promoted villages (thanks to the promotion), this difference of -3.87 USD in health expenditures must be due to the additional 0.41 percent of households that enrolled in the promoted villages because of the promotion. Therefore, we need to adjust the difference in health expenditures to be able to find the impact of the program on the Enroll-if-promoted. To do this, we divide the intention-to-treat estimate— that is, the straight difference between the promoted and nonpromoted groups—by the percentage of Enroll-if-promoted: -3.87 / 0.41 = -9.50. Your colleague, an econometrician who suggests using the randomized promotion as an IV, then estimates the impact of the program through a two-stage least-squares procedure. Conduct this estimation with and without covariate adjustment. Interpret. m_cace &lt;- iv_robust(health_expenditures ~ enrolled_rp | promotion_locality, clusters = locality_identifier, data = df %&gt;% filter(round == 1)) m_cace_wcov &lt;- iv_robust(health_expenditures ~ enrolled_rp + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance | promotion_locality + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance , clusters = locality_identifier, data = df %&gt;% filter(round == 1)) htmlreg(list(m_cace, m_cace_wcov), doctype = FALSE, custom.coef.map = list(`enrolled_rp` = &quot;Enrollment&quot;, `(Intercept)` = &quot;Intercept&quot;), custom.model.names = c(&quot;No Covariate Adjustment&quot;, &quot;With Covariate Adjustment&quot;), caption = &quot;Evaluating HISP: Randomized Promotion as an Instrumental Variable&quot;) Evaluating HISP: Randomized Promotion as an Instrumental Variable No Covariate Adjustment With Covariate Adjustment Enrollment -9.50* -9.74* [-11.76; -7.24] [-11.63; -7.86] Intercept 19.65* 29.17* [ 18.70; 20.59] [ 27.49; 30.85] R2 0.22 0.41 Adj. R2 0.22 0.40 Num. obs. 9914 9914 RMSE 10.49 9.17 N Clusters 200 200 * Null hypothesis value outside the confidence interval. What are the key conditions required to accept the results from the randomized promotion evaluation of HISP? There are three basic assumptions required to accept the result from the randomized promotion evaluation of HISP. First, the promoted and nonpromoted villages have the same characteristics before the HISP. This assumption holds because of the randomized assignment of promotion at the village level, and can be verified by comparing the baseline data from both groups. Second, the promotion is effective in encouraging households to enroll in the HISP. This assumption can be verified if the promoted villages have substantially higher enrollments in HISP than nonpromoted villages. Third, we assume the promotion itself does not directly affect health expenditures. This assumption usually can not be verified but is informed by theory and experience. Based on these results, should HISP be scaled up nationally? Based strictly on the estimate from the multivariate linear regression, the HISP should not be scaled up nationally because it decreased health expenditures by 9.74 USD, which is less than the government-determined threshold level of 10USD. However, the 9.74USD estimate is very close to 10 USD. In statistical terms, it is not statistically different from 10 USD. Therefore, you might still argue that the HISP should be expanded nationally. "],
["regression-discontinuity-designs.html", "Chapter 5 Regression Discontinuity Designs", " Chapter 5 Regression Discontinuity Designs Now consider how the regression discontinuity design (RDD) method can be applied to our Health Insurance Subsidy Program (HISP). After doing some more investigation into the design of HISP, you find that in addition to randomly selecting treatment villages, the authorities targeted the program to low-income households using the national poverty line. The poverty line is based on a poverty index that assigns each household in the country a score between 20 and 100 based on its assets, housing conditions, and sociodemographic structure. The poverty line has been officially set at 58. This means that all households with a score of 58 or below are classified as poor, and all households with a score of more than 58 are considered to be non-poor. Even in the treatment villages, only poor households are eligible to enroll in HISP. Your data set includes information on both poor and non-poor households in the treatment villages. # Create data subset with only treatment localities df_treat &lt;- df %&gt;% filter(treatment_locality == 1) Before carrying out the regression discontinuity design estimations, you decide to check whether there is any evidence of manipulation of the eligibility index. As a first step, you check whether the density of the eligibility index raises any concerns about manipulation of the index. You plot the percentage of households against the baseline poverty index. ggplot(df_treat, aes(x = poverty_index)) + geom_vline(xintercept = 58) + geom_density() + labs(x = &quot;Poverty Index&quot;) We can also conduct a McCreary density test, to examine this more formally. test_density &lt;- rdplotdensity(rdd = rddensity(df_treat$poverty_index, c = 58), X = df_treat$poverty_index, type = &quot;both&quot;) The figures do not indicate any “bunching” of households right below the cutoff of 58. Next, you check whether households respected their assignment to the treatment and comparison groups on the basis of their eligibility score. You plot participation in the program against the baseline poverty index and find that two years after the start of the pilot, only households with a score of 58 or below (that is, to the left of the poverty line) have been allowed to enroll in HISP. In addition, all of the eligible households enrolled in HISP. In other words, you find full compliance and have a “sharp” RDD. ggplot(df_treat, aes(y = enrolled, x = poverty_index)) + geom_vline(xintercept = 58) + geom_point() + labs(x = &quot;Poverty Index&quot;, y = &quot;Enrolled&quot;) You now proceed to apply the RDD method to compute the impact of the program. Using follow-up data, you again plot the relationship between the scores on the poverty index and predicted health expenditures and find the relation illustrated in figure X. In the relationship between the poverty index and the predicted health expenditures, you find a clear break, or discontinuity, at the poverty line (58). df_treat %&gt;% filter(round == 1) %&gt;% mutate(enrolled_lab = ifelse(enrolled == 1, &quot;Enrolled&quot;, &quot;Not Enrolled&quot;)) %&gt;% ggplot(aes(x = poverty_index, y = health_expenditures, group = enrolled_lab, colour = enrolled_lab, fill = enrolled_lab)) + geom_point(alpha = 0.03) + geom_smooth(method = &quot;lm&quot;) + labs(x = &quot;Poverty Index&quot;, y = &quot;Health Expenditures&quot;) + scale_colour_viridis_d(&quot;Enrollment:&quot;, end = 0.7) + scale_fill_viridis_d(&quot;Enrollment:&quot;, end = 0.7) + theme(legend.position=&quot;bottom&quot;) The discontinuity reflects a decrease in health expenditures for those households eligible to receive the program. Given that households on both sides of the cutoff score of 58 are very similar, the plausible explanation for the different level of health expenditures is that one group of households was eligible to enroll in the program and the other was not. You estimate this difference through a regression with the findings shown in the following table. df_treat &lt;- df_treat %&gt;% mutate(poverty_index_c0 = poverty_index - 58) out_rdd &lt;- lm_robust(health_expenditures ~ poverty_index_c0 * enrolled + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance, data = df_treat %&gt;% filter(round == 1)) htmlreg(out_rdd, doctype = FALSE, custom.coef.map = list(&#39;enrolled&#39; = &quot;Enrollment&quot;), caption = &quot;Evaluating HISP: Regression Discontinuity Design with Regression Analysis&quot;, caption.above = TRUE) Evaluating HISP: Regression Discontinuity Design with Regression Analysis Model 1 Enrollment -9.03* [-9.90; -8.16] R2 0.46 Adj. R2 0.46 Num. obs. 4960 RMSE 9.14 * 0 outside the confidence interval. Note: We could also estimate the effect of the program in the following ways Estimating the effect of the program on health expenditures again using regression, but include an interaction with a cubic polynomial of the running variable. out_rdd_cubic &lt;- lm_robust(health_expenditures ~ enrolled * poverty_index_c0 + enrolled * I(poverty_index_c0^2) + enrolled * I(poverty_index_c0^3) + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance, data = df_treat %&gt;% filter(round == 1)) Estimating the effect of the program on health expenditures again using regression, but only including observations 5 points above or below the cutoff of 58. out_rdd5 &lt;- lm_robust(health_expenditures ~ enrolled * poverty_index_c0 + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance, data = df_treat %&gt;% filter(round == 1 &amp; abs(poverty_index_c0) &lt;=5)) Combining all these results together we see a consistent effect of the program. htmlreg(list(out_rdd, out_rdd_cubic, out_rdd5), doctype = FALSE, custom.model.names = c(&quot;Linear&quot;, &quot;Cubic&quot;, &quot;5 Point Window&quot;), custom.coef.map = list(&#39;enrolled&#39; = &quot;Enrollment&quot;), caption = &quot;Evaluating HISP: Regression Discontinuity Design with Regression Analysis&quot;, caption.above = TRUE) Evaluating HISP: Regression Discontinuity Design with Regression Analysis Linear Cubic 5 Point Window Enrollment -9.03* -8.94* -8.54* [-9.90; -8.16] [-10.42; -7.46] [-10.23; -6.86] R2 0.46 0.46 0.41 Adj. R2 0.46 0.46 0.40 Num. obs. 4960 4960 1879 RMSE 9.14 9.14 9.26 * Null hypothesis value outside the confidence interval. Is the result of the RDD analysis valid for all eligible households? No, the RDD estimates represent the effects for households very close to the cutoff poverty index score. Intuitively, this is the region where eligible and ineligible households have most similar characteristics and as such can be compared. Compared with the impact estimated with the randomized assignment method, what does this result say about those households with a poverty index of just under 58? This result says that households just under the poverty line have a slightly smaller reduction in health expenditures than the average eligible household (about $1 less). Households with a poverty index just under 58 will spend on average $9.03 less on health as a result of the HISP. This is less than the result in randomized assignment, which was an average decrease in health expenditures of $10. Based on the RDD impact estimates, should the HISP be scaled up nationally? No, based on this result, the HISP should not be scaled up nationally because it decreased health expenditures by less than the $10 threshold level. "],
["difference-in-differences.html", "Chapter 6 Difference-in-Differences", " Chapter 6 Difference-in-Differences Difference-in-differences can be used to evaluate our Health Insurance Subsidy Program (HISP). In this scenario, you have two rounds of data on two groups of households: one group that enrolled in the program, and another that did not. Remembering the case of the enrolled and non- enrolled groups, you realize that you cannot simply compare the average health expenditures of the two groups because of selection bias. Because you have data for two periods for each household in the sample, you can use those data to solve some of these challenges by comparing the change in health expenditures for the two groups, assuming that the change in the health expenditures of the non-enrolled group reflects what would have happened to the expenditures of the enrolled group in the absence of the program. Note that it does not matter which way you calculate the double difference. Next, you estimate the effect using regression analysis. Using a simple linear regression to compute the simple difference-in- differences estimate, you find that the program reduced household health expenditures by US$8.16. You then refine your analysis by adding additional control variables. In other words, you use a multivariate linear regression that takes into account a host of other factors, and you find the same reduction in household health expenditures. out_did &lt;- lm_robust(health_expenditures ~ round * enrolled, data = df %&gt;% filter(treatment_locality == 1), clusters = locality_identifier) out_did_wcov &lt;- lm_robust(health_expenditures ~ round * enrolled + age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous + hhsize + dirtfloor + bathroom + land + hospital_distance, data = df %&gt;% filter(treatment_locality == 1), clusters = locality_identifier) htmlreg(list(out_did, out_did_wcov), doctype = FALSE, custom.coef.map = list(&#39;enrolled&#39; = &quot;Enrollment&quot;, &#39;round&#39; = &quot;Round&quot;, &#39;round:enrolled&#39; = &quot;Enrollment X Round&quot;), caption = &quot;Evaluating HISP: Difference-in-Differences with Regression&quot;, caption.above = TRUE, custom.model.names = c(&quot;No Covariate Adjustment&quot;, &quot;With Covariate Adjustment&quot;)) Evaluating HISP: Difference-in-Differences with Regression No Covariate Adjustment With Covariate Adjustment Enrollment -6.30* -1.51* [-6.69; -5.91] [-1.77; -1.25] Round 1.51* 1.45* [ 0.79; 2.24] [ 0.73; 2.17] Enrollment X Round -8.16* -8.16* [-8.81; -7.52] [-8.81; -7.52] R2 0.34 0.55 Adj. R2 0.34 0.55 Num. obs. 9919 9919 RMSE 7.91 6.54 N Clusters 100 100 * Null hypothesis value outside the confidence interval. What are the basic assumptions required to accept this result from difference-in-differences? To accept this result, we assume that there are no differential time varying factors between the two groups other than the program. We assume that the treatment and comparison groups would have equal trends or changes in outcomes in the absence of treatment. While this assumption can’t be tested in the postintervention period, we can compare trends before the intervention starts. Based on the result from difference-in-differences, should HISP be scaled up nationally? No, based on this result, the HISP should not be scaled up nationally because it has decreased health expenditures by less than the $10 threshold level. Taking the estimated impact under random assignment as the “true” impact of the program suggests that the difference in difference estimate may be biased. In fact, in this case, using the nonenrolled households as a comparison group does not accurately represent the counterfactual trend in health expenditures. "],
["matching.html", "Chapter 7 Matching", " Chapter 7 Matching Having learned about matching techniques, you may wonder whether you could use them to estimate the impact of the Health Insurance Subsidy Program (HISP). You decide to use some matching techniques to select a group of nonenrolled households that look similar to the enrolled households based on baseline observed characteristics. To do so, you will conduct Propensity Score Matching (PSM). The Propensity Score is the probability that a household will enroll in the program based on the observed values of characteristics (the explanatory variables), such as the age of the household head and of the spouse, their level of education, whether the head of the household is a female, whether the household is indigenous, and so on. Before we start we need to put the data in wide format. Currently a household covers multiple rows in our dataset, as variables are measured pre- and post-enrollment. As we want to match households, we instead each row to be a unique household. Therefore, we have to widen the dataset, by creating separate columns for household characteristics in each time period. df_w &lt;- df %&gt;% pivot_wider(names_from = round, # variable that determines new columns # variables that should be made &quot;wide&quot; values_from = c(health_expenditures, poverty_index, age_hh, age_sp, educ_hh, educ_sp, female_hh, indigenous, hhsize, dirtfloor, bathroom, land, hospital_distance, hospital)) %&gt;% # this is a hack for now as there is one household that has missing values # and missing values are not allowed when using matchit filter(!is.na(health_expenditures_0)) We will carry out matching using two scenarios. In the first scenario, there is a large set of variables to predict enrollment, including socioeconomic household characteristics. In the second scenario, there is little information to predict enrollment (only education and age of the household head). Estimate the Propensity Score # We&#39;ll conduct propensity score estimation and matching at the same # time, as the matchit function does this for us psm_r &lt;- matchit(enrolled ~ age_hh_0 + educ_hh_0, data = df_w %&gt;% dplyr::select(-hospital_0, -hospital_1), distance = &quot;probit&quot;) psm_ur &lt;- matchit(enrolled ~ age_hh_0 + educ_hh_0 + age_sp_0 + educ_sp_0 + female_hh_0 + indigenous_0 + hhsize_0 + dirtfloor_0 + bathroom_0 + land_0 + hospital_distance_0, data = df_w %&gt;% dplyr::select(-hospital_0, -hospital_1), distance = &quot;probit&quot;) htmlreg(list(psm_r$model, psm_ur$model), doctype = FALSE, custom.coef.map = list(&#39;age_hh_0&#39; = &quot;Age (HH) at Baseline&quot;, &#39;educ_hh_0&#39; = &quot;Education (HH) at Baseline&quot;, &#39;age_sp_0&#39; = &quot;Age (Spouse) at Baseline&quot;, &#39;educ_sp_0&#39; = &quot;Education (Spouse) at Baseline&quot;, &#39;female_hh_0&#39; = &quot;Female Head of Household (HH) at Baseline&quot;, &#39;indigenous_0&#39; = &quot;Indigenous Language Spoken at Baseline&quot;, &#39;hhsize_0&#39; = &quot;Number of Household Members at Baseline&quot;, &#39;dirtfloor_0&#39; = &quot;Dirt floor at Baseline&quot;, &#39;bathroom_0&#39; = &quot;Private Bathroom at Baseline&quot;, &#39;land_0&#39; = &quot;Hectares of Land at Baseline&quot;, &#39;hospital_distance_0&#39; = &quot;Distance From Hospital at Baseline&quot;), caption = &quot;Estimating the Propensity Score Based on Baseline Observed Characteristics&quot;, custom.model.names = c(&quot;Limited Set&quot;, &quot;Full Set&quot;)) Estimating the Propensity Score Based on Baseline Observed Characteristics Limited Set Full Set Age (HH) at Baseline -0.02*** -0.01*** (0.00) (0.00) Education (HH) at Baseline -0.04*** -0.02*** (0.01) (0.01) Age (Spouse) at Baseline -0.01*** (0.00) Education (Spouse) at Baseline -0.02* (0.01) Female Head of Household (HH) at Baseline -0.02 (0.05) Indigenous Language Spoken at Baseline 0.16*** (0.03) Number of Household Members at Baseline 0.12*** (0.01) Dirt floor at Baseline 0.38*** (0.03) Private Bathroom at Baseline -0.12*** (0.03) Hectares of Land at Baseline -0.03*** (0.01) Distance From Hospital at Baseline 0.00*** (0.00) AIC 11658.35 11037.04 BIC 11679.96 11123.46 Log Likelihood -5826.18 -5506.52 Deviance 11652.35 11013.04 Num. obs. 9913 9913 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 As shown in the above table, the likelihood that a household is enrolled in the program is smaller if the household is older, more educated, headed by a female, has a bathroom, or owns larger amounts of land. By contrast, being indigenous, having more household members, having a dirt floor, and being located further from a hospital all increase the likelihood that a household is enrolled in the program. So overall, it seems that poorer and less-educated households are more likely to be enrolled, which is good news for a program that targets poor people. Plot the distribution of the Propensity Score by enrollment. What can we say about common support? df_w &lt;- df_w %&gt;% mutate(ps_ur = psm_ur$model$fitted.values) df_w %&gt;% mutate(enrolled_lab = ifelse(enrolled == 1, &quot;Enrolled&quot;, &quot;Not Enrolled&quot;)) %&gt;% ggplot(aes(x = ps_ur, group = enrolled_lab, colour = enrolled_lab, fill = enrolled_lab)) + geom_density(alpha = I(0.2)) + xlab(&quot;Propensity Score&quot;) + scale_fill_viridis_d(&quot;Status:&quot;, end = 0.7) + scale_colour_viridis_d(&quot;Status:&quot;, end = 0.7) + theme(legend.position = &quot;bottom&quot;) Figure 7.1: Distribution of Propensity Score by Enrollment Status You check the distribution of the propensity score for the enrolled and matched comparison households. Figure 7.1 shows that common support (when using the full set of explanatory variables) extends across the whole distribution of the propensity score. In fact, none of the enrolled households fall outside the area of common support. In other words, we are able to find a matched comparison household for each of the enrolled households. Did matching by the propensity score improve balance? kable(summary(psm_ur)$sum.matched, caption = &quot;Balance Before Matching&quot;) %&gt;% kable_styling() Table 7.1: Balance Before Matching Means Treated Means Control SD Control Mean Diff eQQ Med eQQ Mean eQQ Max distance 0.3694119 0.3687162 0.1289918 0.0006957 0.0001013 0.0007221 0.0167152 age_hh_0 41.6565796 41.7867746 13.1422452 -0.1301951 1.0000000 0.8650129 5.0000000 educ_hh_0 2.9711803 2.9549320 2.7497469 0.0162484 0.0000000 0.1437787 4.0000000 age_sp_0 36.8363698 36.9915655 11.0374258 -0.1551957 1.0000000 0.7699055 8.0000000 educ_sp_0 2.7032726 2.7128880 2.6196748 -0.0096154 0.0000000 0.1378205 4.0000000 female_hh_0 0.0732119 0.0732119 0.2605279 0.0000000 0.0000000 0.0000000 0.0000000 indigenous_0 0.4291498 0.4234143 0.4941832 0.0057355 0.0000000 0.0057355 1.0000000 hhsize_0 5.7699055 5.7884615 2.1411833 -0.0185560 0.0000000 0.1373144 1.0000000 dirtfloor_0 0.7216599 0.7253711 0.4464024 -0.0037112 0.0000000 0.0037112 1.0000000 bathroom_0 0.5735493 0.5732119 0.4946944 0.0003374 0.0000000 0.0003374 1.0000000 land_0 1.6771255 1.7010796 2.6217989 -0.0239541 0.0000000 0.1103239 3.0000000 hospital_distance_0 109.2043122 108.5100383 41.8790212 0.6942738 1.2450775 1.6190618 7.5290520 kable(summary(psm_ur)$sum.all, caption = &quot;Balance After Matching&quot;) %&gt;% kable_styling() Table 7.2: Balance After Matching Means Treated Means Control SD Control Mean Diff eQQ Med eQQ Mean eQQ Max distance 0.3694119 0.2683525 0.1435197 0.1010594 0.1109167 0.1010943 0.1284425 age_hh_0 41.6565796 48.1384372 15.5146171 -6.4818576 7.0000000 6.4925432 10.0000000 educ_hh_0 2.9711803 2.7744736 2.7971992 0.1967067 0.0000000 0.3312010 4.0000000 age_sp_0 36.8363698 41.6117427 12.9925496 -4.7753729 5.0000000 4.7908232 9.0000000 educ_sp_0 2.7032726 2.5810189 2.5713309 0.1222538 0.0000000 0.2663630 4.0000000 female_hh_0 0.0732119 0.1100878 0.3130217 -0.0368759 0.0000000 0.0367746 1.0000000 indigenous_0 0.4291498 0.3203339 0.4666384 0.1088159 0.0000000 0.1089744 1.0000000 hhsize_0 5.7699055 4.9263203 2.2276936 0.8435852 1.0000000 0.8468286 2.0000000 dirtfloor_0 0.7216599 0.5533170 0.4971849 0.1683429 0.0000000 0.1683536 1.0000000 bathroom_0 0.5735493 0.6340481 0.4817307 -0.0604988 0.0000000 0.0603914 1.0000000 land_0 1.6771255 2.2511153 3.3057321 -0.5739898 0.0000000 0.5779352 5.0000000 hospital_distance_0 109.2043122 103.6626222 42.0414242 5.5416899 5.2651255 5.7016559 13.5770481 Using the matched sample, what is the estimated effect of the program? To obtain the estimated impact using the matching method, we first need to extract the matched data set. match_df_r &lt;- match.data(psm_r) match_df_ur &lt;- match.data(psm_ur) We can then estimate the effect of the program using a (weighted) linear regression. In this case all weights are equal to 1, meaning there is no need to use the weights, as we have one to one matching without replacement. out_lm_r &lt;- lm_robust(health_expenditures_1 ~ enrolled, data = match_df_r, clusters = locality_identifier, weights = weights) out_lm_ur &lt;- lm_robust(health_expenditures_1 ~ enrolled, data = match_df_ur, clusters = locality_identifier, weights = weights) htmlreg(list(out_lm_r, out_lm_ur), doctype = FALSE, caption = &quot;Evaluating HISP: Matching on Baseline Characteristics and Regression Analysis&quot;, custom.model.names = c(&quot;Limited Set&quot;, &quot;Full Set&quot;)) Evaluating HISP: Matching on Baseline Characteristics and Regression Analysis Limited Set Full Set (Intercept) 19.57* 17.84* [ 18.93; 20.20] [ 17.27; 18.41] enrolled -11.73* -10.00* [-12.48; -10.98] [-10.73; -9.27] R2 0.29 0.28 Adj. R2 0.29 0.28 Num. obs. 5928 5928 RMSE 9.20 8.03 N Clusters 197 197 * Null hypothesis value outside the confidence interval. Table X shows that the impact estimated from applying this procedure is a reduction of US$10.00 in household health expenditures when matching on the full set of covariates. You realize that you also have information on baseline outcomes in your survey data, so you decide to carry out matched difference-in-differences in addition to using the full set of explanatory variables. To do so we merge the matching weights into the original data frame, allowing us to remove observations that were not matched while keeping the panel data format needed for a difference-in-differences regression. # limited set of covariates df_long_match_r &lt;- df %&gt;% left_join(match_df_r %&gt;% dplyr::select(household_identifier, weights)) %&gt;% filter(!is.na(weights)) ## Joining, by = &quot;household_identifier&quot; # full set of covaraites df_long_match_ur &lt;- df %&gt;% left_join(match_df_ur %&gt;% dplyr::select(household_identifier, weights)) %&gt;% filter(!is.na(weights)) ## Joining, by = &quot;household_identifier&quot; We can now estimate the difference-in-differences regression. did_reg_r &lt;- lm_robust(health_expenditures ~ enrolled * round, data = df_long_match_r, weights = weights, clusters = locality_identifier) did_reg_ur &lt;- lm_robust(health_expenditures ~ enrolled * round, data = df_long_match_ur, weights = weights, clusters = locality_identifier) htmlreg(list(did_reg_r, did_reg_ur), doctype = FALSE, custom.coef.map = list(&#39;enrolled&#39; = &quot;Enrollment&quot;, &#39;round&#39; = &quot;Round&quot;, &#39;enrolled:round&#39; = &quot;Enrollment X Round&quot;), caption = &quot;Evaluating HISP: Difference-in-Differences Regression Combined With Matching&quot;, custom.model.names = c(&quot;Limited Set&quot;, &quot;Full Set&quot;), caption.above = TRUE) Evaluating HISP: Difference-in-Differences Regression Combined With Matching Limited Set Full Set Enrollment -2.68* -0.54* [-3.20; -2.17] [ -1.01; -0.07] Round 2.39* 2.81* [ 1.92; 2.87] [ 2.35; 3.26] Enrollment X Round -9.04* -9.46* [-9.62; -8.46] [-10.05; -8.87] R2 0.26 0.24 Adj. R2 0.26 0.24 Num. obs. 11856 11856 RMSE 7.35 6.53 N Clusters 197 197 * Null hypothesis value outside the confidence interval. We estimate that enrollment reduced health expenditures by approximately 9 Dollars. What are the basic assumptions required to accept these results based on the matching method? To accept this result, we assume that there are no unobserved differences in the two groups that can be associated with health expenditures. This assumption is necessary because you can only use observed differences when matching households in the two groups. Why are the results from the matching method different if you use the full versus the limited set of explanatory variables? There might be some variables that are excluded from the limited set of explanatory variables that do affect both participation in the program and health expenditures. Omitting these variables will bias the impact estimate. What happens when you compare the results from the matching method with the result form randomized assignment? Why do you think the results are so different for matching on a limited set of explanatory variables? Why is the result more similar when matching on a full set of explanatory variables? Randomized assignment and matching primarily differ in how the treatment is given. In randomized assignment, the HISP is randomly assigned and the impact is measured by the difference in health expenditures between the treatment and comparison groups. In matching, the HISP is not randomly assigned. A comparison group is constructed from nonenrolled households that have similar characteristics to enrolled households using matching. When matching on a limited set of explanatory variables, the remaining unobserved differences in the matched comparison group likely account for some of these difference between the matching and the randomized assignment estimates. When matching on a full set of explanatory variables, the difference between the matching and randomized assignment estimates tends to get smaller. However, you cannot be sure that all relevant explanatory variables are accounted for. Based on the result from the matching method, should the HISP be scaled up nationally? Based strictly on the estimate from matching on a full set of explanatory variables, the HISP should not be scaled up nationally because it decreased health expenditures by $ 9.95, which is less than the government-determined threshold level of $10. However, the $9.95 estimate is very close to $10. In statistical terms, it is not statistically different from $10. Therefore, you might still argue that the HISP should be expanded nationally. "],
["design-and-sampling.html", "Chapter 8 Design and Sampling 8.1 Power Calculations with Clusters", " Chapter 8 Design and Sampling Let us say that the ministry of health was pleased with the quality and results of the evaluation of the Health Insurance Subsidy Program (HISP). However, before scaling up the pro- gram, the ministry decides to pilot an expanded version of the program, which they call HISP+. The original HISP pays for part of the cost of health insurance for poor rural households, covering costs of primary care and drugs, but it does not cover hospitalization. The minister of health wonders whether an expanded HISP+ that also covers hospitalization would further lower out-of-pocket health expenditures of poor households. The ministry asks you to design an impact evaluation to assess whether HISP+ would decrease health expenditures for poor rural households. In this case, choosing an impact evaluation design is not a challenge for you: HISP+ has limited resources and cannot be implemented universally immediately. As a result, you have concluded that randomized assignment would be the most viable and robust impact evaluation method. The minister of health understands how well the randomized assignment method can work and is supportive. To finalize the design of the impact evaluation, you have hired a statistician who will help you establish how big a sample is needed. Before they start working, the statistician asks you for some key inputs. They uses a checklist of five questions. 1. Will the HISP+ program generate clusters? At this point, you are not totally sure. You believe that it might be possible to randomize the expanded benefit package at the household level among all poor rural households that already benefit from HISP. However, you are aware that the minister of health may prefer to assign the expanded program at the village level, and that would create clusters. The statistician sug- gests conducting power calculations for a benchmark case without clusters, and then considering how results would change with clusters. 2. What is the outcome indicator? You explain that the government is interested in a well-defined indicator: out-of-pocket health expenditures of poor households. The statistician looks for the most up-to-date source to obtain benchmark values for this indicator and suggests using the follow-up survey from the HISP evaluation. They notes that among households that received HISP, the per capita yearly out-of-pocket health expenditures have averaged US$7.84. 3. What is the minimum level of impact that would justify the investment in the intervention? In other words, what decrease in out-of-pocket health expenditures below the average of US$7.84 would make this intervention worthwhile? The statistician stresses that this is not only a technical consideration, but truly a policy question; that is why a policy maker like you must set the minimum effect that the evaluation should be able to detect. You remember that based on ex ante economic analysis, the HISP+ program would be considered effective if it reduced household out-of-pocket health expenditures by US$2. Still, you know that for the purpose of the evaluation, it may be better to be conservative in deter- mining the minimum detectable impact, since any smaller impact is unlikely to be captured. To understand how the required sample size varies based on the minimum detectable effect, you suggest that the statistician perform calculations for a minimum reduction of out-of-pocket health expenditures of US$1, US$2, and US$3. 4. What is the variance of the outcome indicator in the population of interest? The statistician goes back to the data set of treated HISP households, pointing out that the standard deviation of out-of-pocket health expenditures is US$8. 5. What would be a reasonable level of power for the evaluation being conducted? The statistician adds that power calculations are usually conducted for a power between 0.8 and 0.9. They recommends 0.9, but offers to perform robustness checks later for a less conservative level of 0.8. We can calculate all the summary statistics we need as follows # mean and standard deviation of outcome sumstats &lt;- df_elig %&gt;% filter(round == 1 &amp; treatment_locality == 1) %&gt;% summarise(mean_health = mean(health_expenditures), sd_health = sd(health_expenditures), mean_hospital = mean(hospital), sd_hospital = sd(hospital)) Equipped with all this information, the statistician undertakes the power calculations. power_calc_health &lt;- tibble(d_health_expenditures = rep(-1:-3,2), power = rep(c(0.8, 0.9), each = 3)) %&gt;% mutate(n_required = map2(d_health_expenditures, power, ~ {pwr.t.test(d = .x / sumstats$sd_health, sig.level = 0.05, power = .y)$n}) %&gt;% unlist() %&gt;% ceiling()) As agreed, they first present the more conservative case of a power of 0.9. power_calc_health %&gt;% filter(power == 0.9) %&gt;% mutate(mde = gsub(&quot;-&quot;, &quot;$&quot;, d_health_expenditures)) %&gt;% select(mde, power, n_required) %&gt;% kable(align = &quot;c&quot;, col.names = c(&quot;Minimum Detectable Effect&quot;, &quot;Power&quot;, &quot;Sample Required per Group&quot;), caption = &quot;Evaluating HISP+: Sample Size Required to Detect Various Minimum Detectable Effects, Power = 0.9&quot;) %&gt;% kable_styling(full_width = TRUE) Table 8.1: Evaluating HISP+: Sample Size Required to Detect Various Minimum Detectable Effects, Power = 0.9 Minimum Detectable Effect Power Sample Required per Group $1 0.9 1345 $2 0.9 337 $3 0.9 151 The statistician concludes that to detect a US$2 decrease in out-of-pocket health expenditures with a power of 0.9, the sample needs to contain at least 672 units (336 treated units and 336 comparison units, with no clustering). They notes that if you were satisfied to detect a US$3 decrease in out-of-pocket health expenditures, a smaller sample of at least 300 units (150 units in each group) would be sufficient. By contrast, a much larger sample of at least 2,688 units (1,344 in each group) would be needed to detect a US$1 decrease in out-of-pocket health expenditures. The statistician then produces another table for a power level of 0.8. power_calc_health %&gt;% filter(power == 0.8) %&gt;% mutate(mde = gsub(&quot;-&quot;, &quot;$&quot;, d_health_expenditures)) %&gt;% select(mde, power, n_required) %&gt;% kable(align = &quot;c&quot;, col.names = c(&quot;Minimum Detectable Effect&quot;, &quot;Power&quot;, &quot;Sample Required per Group&quot;), caption = &quot;Evaluating HISP+: Sample Size Required to Detect Various Minimum Detectable Effects, Power = 0.8&quot;) %&gt;% kable_styling(full_width = TRUE) Table 8.2: Evaluating HISP+: Sample Size Required to Detect Various Minimum Detectable Effects, Power = 0.8 Minimum Detectable Effect Power Sample Required per Group $1 0.8 1005 $2 0.8 252 $3 0.8 113 The table shows that the required sample sizes are smaller for a power of 0.8 than for a power of 0.9. To detect a US$2 reduction in household out-of-pocket health expenditures, a total sample of at least 502 units would be sufficient. To detect a US$3 reduction, at least 224 units are needed. However, to detect a US$1 reduction, at least 2,008 units would be needed in the sample. The statistician stresses that the following results are typical of power calculations: The higher (more conservative) the level of power, the larger the required sample size. The smaller the impact to be detected, the larger the required sample size. The statistician asks whether you would like to conduct power calculations for other outcomes of interest. You suggest also considering the sample size required to detect whether HISP+ affects the hospitalization rate. In the sample of treated HISP villages, a household member visits the hospital in a given year in 5 percent of households; this provides a benchmark rate. power_calc_hospital &lt;- tibble(d_hospital = rep(c(-.01,-.02, -.03),2), power = rep(c(0.8, 0.9), each = 3)) %&gt;% mutate(n_required = map2(d_hospital, power, ~ {pwr.t.test(d = .x / sumstats$sd_hospital, sig.level = 0.05, power = .y)$n}) %&gt;% unlist() %&gt;% ceiling ()) The statistician produces a new table, which shows that relatively large samples would be needed to detect changes in the hospitalization rate of 1, 2, or 3 percentage points from the baseline rate of 5 percent. power_calc_hospital %&gt;% filter(power == 0.8) %&gt;% mutate(mde = gsub(&quot;-&quot;, &quot;&quot;, d_hospital * 100)) %&gt;% select(mde, power, n_required) %&gt;% kable(align = &quot;c&quot;, col.names = c(&quot;Minimum Detectable Effect (%)&quot;, &quot;Power&quot;, &quot;Sample Required per Group&quot;), caption = &quot;Evaluating HISP+: Sample Size Required to Detect Various Minimum Desired Effects (Increase in Hospitalization Rate)&quot;) %&gt;% kable_styling(full_width = TRUE) Table 8.3: Evaluating HISP+: Sample Size Required to Detect Various Minimum Desired Effects (Increase in Hospitalization Rate) Minimum Detectable Effect (%) Power Sample Required per Group 1 0.8 7257 2 0.8 1815 3 0.8 808 The table shows that sample size requirements are larger for this outcome (the hospitalization rate) than for out-of-pocket health expenditures. The statistician concludes that if you are interested in detecting impacts on both outcomes, you should use the larger sample sizes implied by the power calculations performed on the hospitalization rates. If sample sizes from the power calculations performed for out-of-pocket health expenditures are used, the statistician suggests letting the minister of health know that the evaluation will not have sufficient power to detect policy-relevant effects on hospitalization rates. Which sample size would you recommend to estimate the impact of HISP+ on out-of-pocket health expenditures? This answer will depend on policy priorities and available budgets. Under randomized assignment at the individual level, a total sample size of 2,688 units (1,344 in each group) would be needed to detect a $1 decrease in out-of-pocket health expenditures with a power of 0.9. A total sample size of 672 (336 treated and 336 comparison units) would detect a change as small as $2 in health expenditures at the 0.9 power. This would cut the required sample and related data collection costs substantially. At the same time, it would still allow detecting the impacts that would make the program effective based on the ex-ante economic analysis. As such, such a sample may be a good compromise if budgets are limited. Would that sample size be sufficient to detect changes in the hospitalization rate? A sample size of 672 would not be sufficient to detect even a 3 percent change in hospitalization rate with a power of 0.9. Much larger sample sizes (above 1,614) will be required to detect impacts on hospitalization rates. 8.1 Power Calculations with Clusters After your first discussion with the statistician about power calculations for HISP+, you decided to talk briefly to the minister of health about the implications of randomly assigning the expanded HISP+ benefits among all individuals in the population who receive the basic HISP plan. The consultation revealed that such a procedure would not be politically feasible: in that context, it would be hard to explain why one person would receive the expanded benefits, while her neighbor would not. Instead of randomization at the individual level, you therefore suggest randomly selecting a number of HISP villages to pilot HISP+. All villagers in the selected village would then become eligible. This procedure will create clusters and thus require new power calculations. You now want to determine how large a sample is required to evaluate the impact of HISP+ when it is randomly assigned by cluster. You consult with your statistician again. They reassures you: only a little more work is needed. On their checklist, only one question is left unanswered. They needs to know how variable the outcome indicator is within clusters. Luckily, this is also a question they can answer using the HISP data. They finds that the within-village correlation of out-of-pocket health expenditures is equal to 0.04. # intraclass correlation, for cluster calculations df_elig_t1r1 &lt;- df_elig %&gt;% filter(round == 1 &amp; treatment_locality == 1) %&gt;% select(health_expenditures, locality_identifier) icc_est &lt;- clus.rho(df_elig_t1r1$health_expenditures, df_elig_t1r1$locality_identifier, type = 3)$icc icc_est ## value ## ANOVA rho 0.04061629 They also ask whether an upper limit has been placed on the number of villages in which it would be feasible to implement the new pilot. Since the program now has 100 HISP villages, you explain that you could have, at most, 50 treatment villages and 50 comparison villages for HISP+. With that information, the statistician produces the power calculations shown in for a power of 0.8. # calculating all at once power_clstr_calc_health &lt;- tibble(d_health_expenditures = -1:-3) %&gt;% mutate(n_required = map(d_health_expenditures, ~ {crtpwr.2mean(d = .x, m = 50, alpha = 0.05, power = 0.8, cv = 0, icc = icc_est, varw = sumstats$sd_health^2)}) %&gt;% unlist() %&gt;% ceiling()) power_clstr_calc_health %&gt;% mutate(mde = gsub(&quot;-&quot;, &quot;$&quot;, d_health_expenditures), total_clusters = 50 * 2, total_sample = total_clusters * n_required) %&gt;% select(mde, total_clusters, n_required, total_sample) %&gt;% kable(col.names = c(&quot;Minimum Detectable Effect&quot;, &quot;Number of Clusters&quot;, &quot;Units per Cluster&quot;, &quot;Total Observations&quot;), align = &quot;c&quot;) %&gt;% kable_styling(full_width = TRUE) Minimum Detectable Effect Number of Clusters Units per Cluster Total Observations $1 100 117 11700 $2 100 7 700 $3 100 3 300 The statistician concludes that to detect a US$2 decrease in out-of-pocket health expenditures, the sample must include at least 700 units: that is, 7 units per cluster in 100 clusters (50 clusters in the treatment group and 50 clusters in the comparison group). They note that this number is higher than in the sample under randomized assignment at the household level, which required only a total of 504 units (252 in the treatment group and 252 in the comparison group). To detect a US$3 decrease in out-of-pocket health expenditures, the sample would need to include at least 300 units, or 3 units in each of 100 clusters (50 clusters in the treatment group and 50 clusters in the comparison group). The statistician then shows you how the total number of observations required in the sample varies with the total number of clusters. He decides to repeat the calculations for a minimum detectable effect of US$2 and a power of 0.8. The size of the total sample required to estimate such an effect increases strongly when the number of clusters diminishes. With 120 clusters, a sample of 600 observations would be needed. If only 30 clusters were available, the total sample would need to contain 1,920 observations. By contrast, if 90 clusters were available, only 720 observations would be needed. # calculating all at once power_clstr_n_calc_health &lt;- tibble(n_clusters = c(15, 29, 40.5, 45, 60)) %&gt;% mutate(n_required = map(n_clusters, ~ {crtpwr.2mean(m = .x, d = 2, alpha = 0.05, power = 0.8, cv = 0, icc = icc_est, varw = sumstats$sd_health^2)}) %&gt;% unlist() %&gt;% ceiling()) power_clstr_n_calc_health %&gt;% mutate(mde = &quot;$2&quot;, # multiply clusters by 2, as power calculator works with number of # clusters per group (not total number of clusters) total_clusters = 2 * n_clusters, total_sample = total_clusters * n_required) %&gt;% select(mde, total_clusters, n_required, total_sample) %&gt;% kable(col.names = c(&quot;Minimum Detectable Effect&quot;, &quot;Number of Clusters&quot;, &quot;Units per Cluster&quot;, &quot;Total Observations&quot;), align = &quot;c&quot;) %&gt;% kable_styling(full_width = TRUE) Minimum Detectable Effect Number of Clusters Units per Cluster Total Observations $2 30 64 1920 $2 58 14 812 $2 81 9 729 $2 90 8 720 $2 120 5 600 Which total sample size would you recommend to estimate the impact of HISP+ on out-of-pocket health expenditures? This answer will depend on policy priorities and available budgets. A total sample size of 600 households (with 120 villages and 5 households per village) would be appropriate for the evaluation, as this sample size would detect a change of $2 with a power of 0.8. In how many villages would you advise the minister of health to roll out HISP+? Power is maximized when the number of treatment and control observations is the same. If a total sample of 90 villages is needed, rolling out HISP+ to 45 villages would maximize power. The other 45 villages would be comparison villages. "],
["session-info.html", "Chapter 9 Session Info", " Chapter 9 Session Info sessionInfo() ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Mojave 10.14.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.0 ## [4] purrr_0.3.4 readr_1.3.1 tidyr_1.1.0 ## [7] tibble_3.0.3 ggplot2_3.3.2 tidyverse_1.3.0 ## [10] texreg_1.37.5 skimr_2.1.2 rddensity_1.0 ## [13] pwr_1.3-0 modelsummary_0.5.0 tables_0.9.3 ## [16] MatchIt_3.0.2 kableExtra_1.1.0 haven_2.3.1 ## [19] fishmethods_1.11-1 estimatr_0.22.0 clusterPower_0.6.111 ## [22] broom_0.7.0 ## ## loaded via a namespace (and not attached): ## [1] nlme_3.1-148 fs_1.4.2 lubridate_1.7.9 ## [4] webshot_0.5.2 httr_1.4.2 repr_1.1.0 ## [7] numDeriv_2016.8-1.1 tools_4.0.2 backports_1.1.8 ## [10] R6_2.4.1 mgcv_1.8-31 DBI_1.1.0 ## [13] colorspace_1.4-1 withr_2.2.0 tidyselect_1.1.0 ## [16] curl_4.3 compiler_4.0.2 cli_2.0.2 ## [19] rvest_0.3.6 xml2_1.3.2 labeling_0.3 ## [22] bookdown_0.20 scales_1.1.1 digest_0.6.25 ## [25] foreign_0.8-80 minqa_1.2.4 rmarkdown_2.3 ## [28] rio_0.5.16 lpdensity_1.0 base64enc_0.1-3 ## [31] pkgconfig_2.0.3 htmltools_0.5.0 lme4_1.1-23 ## [34] highr_0.8 dbplyr_1.4.4 rlang_0.4.7 ## [37] readxl_1.3.1 rstudioapi_0.11 farver_2.0.3 ## [40] generics_0.0.2 jsonlite_1.7.0 zip_2.0.4 ## [43] car_3.0-8 magrittr_1.5 Formula_1.2-3 ## [46] Matrix_1.2-18 Rcpp_1.0.5 munsell_0.5.0 ## [49] fansi_0.4.1 abind_1.4-5 lifecycle_0.2.0 ## [52] stringi_1.4.6 yaml_2.2.1 carData_3.0-4 ## [55] MASS_7.3-51.6 grid_4.0.2 blob_1.2.1 ## [58] crayon_1.3.4 lattice_0.20-41 splines_4.0.2 ## [61] hms_0.5.3 knitr_1.29 pillar_1.4.6 ## [64] ggpubr_0.4.0 boot_1.3-25 ggsignif_0.6.0 ## [67] reprex_0.3.0 glue_1.4.1 evaluate_0.14 ## [70] data.table_1.13.0 modelr_0.1.8 vctrs_0.3.2 ## [73] nloptr_1.2.2.2 cellranger_1.1.0 bootstrap_2019.6 ## [76] gtable_0.3.0 assertthat_0.2.1 openxlsx_4.1.5 ## [79] xfun_0.16 rstatix_0.6.0 viridisLite_0.3.0 ## [82] statmod_1.4.34 ellipsis_0.3.1 "]
]
